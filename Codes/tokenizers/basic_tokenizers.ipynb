{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e27319c",
   "metadata": {},
   "source": [
    "# NLPnLLM Series: A gentle introduction\n",
    "\n",
    "NLP forms the basis of understanding natural languages, and plays a crucial role in the development of Large Language Models. Without understanding how NLP works, and how preliminary research in NLP took place, it is difficult to understand LLMs in detail. So, in this NLPnLLM series, I will uncover basics of NLP, different techniques, models, all the way to LLMs, and will try to give an understanding of years of research process that defines the present state of AI. I will also explain in detail the difference in different processes involved (like Embeddings, tokenization, etc) in NLP and LLM, and what changed from NLP to LLMs that make the current tech much more robust and realistic, resembling human level language understanding, that too in various languages.\n",
    "\n",
    "Here is how I will be uploading the blogs:\n",
    "\n",
    "**Part I - Very basic**\n",
    "\n",
    "Our objective in this module will be to understand very basic reserach in NLP that were useful in understanding and parsing natural language. We will understand how text corpus (collection of texts) is broken down into simple units, how they are represented as numbers and how we work on top of them. We will also write lots of code, building some mini-projects as well.\n",
    "Here are the things we will work on:\n",
    "- Tokenization (Sentence level, word level, character level and subword level tokenization, byte-pair encoding, unigram-lm tokenizer, hugging-face open source tokenizers, etc)\n",
    "- Embeddings (One Hot Code embedding, bag-of-words, TF-IDF, word2vec, attention mechanism embedding and positional embeddings)\n",
    "- Building these from Scratch in python, using libraries like NLTK, gensim and pytorch, using 2 different languages and a few mini projects\n",
    "\n",
    "**Part-II - Intermediate NLP**\n",
    "- Language models (Understanding and building n-grams models, LSTM and RNN language models, etc. We will also go through different sampling techniques helpful in deciding the next word of the language model)\n",
    "- Working on NLP algorithms like GRUs, LSTMs, Bidirectional LSTM and RNNs. Building them from Scratch, and using pytorch on time-series and text data.\n",
    "- Building semantic search, mis-spelled word detection, sentence completion, NER, and other similar projects\n",
    "\n",
    "**Part-III - Advanced NLP**\n",
    "- This portion will consist of an in depth understanding of Encoder-decoder architecture, Bahdanau attention and other pre transformers models.\n",
    "- Understanding of Attention, self-attention, masked-self attention, transformers in detail and building Transformers from Scratch, using pytorch and python.\n",
    "- Exploring Word2Vec, Transformers, Bag-of-trees, ULMfit, Sentence embedding and other different papers.\n",
    "- Understanding and building GPT, and BERT models.\n",
    "\n",
    "*Later, after NLP, we will explore LLMs. And in between, we will keep exploring how these processes are done in modern LLM application, and how they changed or gets replaced. We will understand advantages and dis-advantages of all these processes in detail.*\n",
    "\n",
    "*All the codes can be found at this Github repository: **https://github.com/Harsh-Agarwals/LLMs/tree/main/Codes***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d079077",
   "metadata": {},
   "source": [
    "# Steps in an NLP workflow:\n",
    "\n",
    "- **Data Cleaning**: For any text dataset, the very first is cleaning. The data that we get from different data sources (could be online articles, encyclopedia, news articles, blogs, etc) contains useless whitespaces, next-line characters, HTML tags, spam, duplicated contents (we need to remove duplicates because these can result in overfitting), etc which are needed to be removed. We start with cleaning the data after gathering data from different souces. There are various pre-processing steps involved in this step, some of which are removing stop-words and punctuation, and lowercasing the data.\n",
    "\n",
    "- **Tokenization**: Now once we have the cleaned data, we need to convert this data into numerical format, since computers can only understand numbers. This process is called as embedding, but how will we convert data to numerical vectors? A simple process for this is to convert corpus of data into sentence, or word, or token, or subword, and then converting these to vectors. This process is called as tokenization. There are different types of tokenization like sentence level tokenization, word level tokenization, subword tokenization (using byte pair encoding and used primarily in LLMs and is language independent) and token tokenization. There are various pre-processing steps involved in this step, some of which are stemming and lemmatization.\n",
    "\n",
    "- **Embedding**: After tokenization, we convert tokens/subwords to vectors using embedding techniques. Older techniques includes bag-of-words, TF-IDF, one hotcode encoding, and better techniques are word2vec and glove. In modern LLM applications, we use contextual and positional embedding using attention mechanism.\n",
    "\n",
    "- **Modelling**: Now, once our data is ready, we will train model using this data.\n",
    "\n",
    "- **Output**: Using various sampling techniques, we generate outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cc9e0f",
   "metadata": {},
   "source": [
    "## Basic Tokenization\n",
    "\n",
    "The first step in any NLP pipeline is tokenization. Tokenization is a fundamental process where we break down text into smaller units, such as words, subwords, or characters. Once we have cleaned our data, we need to convert this text into a numerical format because computers can only process numbers. This numerical representation step is called embedding. But before we embed, we need to tokenize. That's where tokenization comes into play.\n",
    "\n",
    "### What is Tokenization and why is it used?\n",
    "\n",
    "Tokenization involves splitting a corpus of text into smaller units: sentences, words, or subwords. These tokens are then used as the basis for vectorization techniques like TF-IDF, bag-of-words, or more advanced embeddings such as Word2Vec or transformers.\n",
    "\n",
    "There are different types of tokenization, link:\n",
    "- sentence level tokenization, \n",
    "- word level tokenization, \n",
    "- subword tokenization (using byte pair encoding and used primarily in LLMs and is language independent) \n",
    "\n",
    "Tokenization is often paired with preprocessing steps like stemming and lemmatization to reduce vocabulary size and improve learning efficiency.\n",
    "\n",
    "In this notebook, we'll understand different methods to tokenize text in a corpus.\n",
    "\n",
    "### How do we tokenize in NLP?\n",
    "\n",
    "**Steps**:\n",
    "\n",
    "***Word level tokenizer***\n",
    "- Remove punctuations\n",
    "- Convert text to lowercase\n",
    "- separating words by whitespace, converting into list\n",
    "- Remove stopwords\n",
    "- Lemmatization or stemming of every leftout word\n",
    "\n",
    "One question must be arriving in your mind, why do we remove punctuations, lowercase alphabets, remove stopwords, etc even though they plays an important role in the language. Now that where these methods fails. \n",
    "\n",
    "We **lowercase because** vocabular for Dog, dog, or DOG, etc is same, and if we include capital letters, our vocabular will shoot up, since there is no limit to such data patterns.\n",
    "\n",
    "Next, **why we remove punctuations?** Because these doesn't help in embedding methods like TF-IDF, bag-of-words, etc which focuses on words and mainly relies on word frequencies. They can shoot up our vocabulary and n-grams combinations too. This is perfectly understood, **but why we remove stopwords?** How does this helps? This question must be coming to your mind now. Let's see that. The reason we remove stopwords is that they occurs very frequently throughtout the texts, and thus provides very less signal to ML models. Removing them reduces noise and model complexity.\n",
    "\n",
    "\n",
    "### Now let's understand Lemmatization and Stemming\n",
    "\n",
    "**Lemmatization**: Breaking word into root word. *Eg. Running -> Run*\n",
    "\n",
    "**Stemming**: Removing affix from the word, may not result in a valid word. *Eg. Running -> Runn*\n",
    "\n",
    "#### Why are these useful?\n",
    "- It makes sure our vocabular size is limited\n",
    "- Generalize to various forms of word\n",
    "- Simplify training for statistical models\n",
    "\n",
    "**Are there any downside to lemmatization and stemming?**\n",
    "\n",
    "What does lemmatization or stemming does? Simply breaking a word into simpler word (either by converting to the base word or by removing grammar). Is this a good idea to drop grammar at all? Grammar represents the core understanding and syntax of the language, and dropping this is not good at all. But we do it because using grammar suffix in words can lead to exploading vocabulary, which can further lead to very sparse encoding. Having a few word with suffix can lead to model not recognizing their importance, under fitting basically.\n",
    "\n",
    "This looks okayish for languages like English with low sets of grammar/suffix. How about hindi or other language with dense suffix/grammar? They can explode up the vocabulary because single word can have multple attributes, forming new words. This would result in a bad under-fitting model. Needless to say, loss of informations is an issue as well. Models will not be able to understand how suffix/grammar relates to words in a sentence. This is why lemmatization and stemming is a flaw, that is needed to be dropped.\n",
    "\n",
    "One question that might come naturally is - if lemmatization and stemming is not good, and can explode our vocabulary, how does LLMs handles grammar and suffix? Again, subword tokenization solves this issue.\n",
    "\n",
    "*Now lets code all these!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d81f8",
   "metadata": {},
   "source": [
    "## Importing libraries\n",
    "\n",
    "Since we are building this tokenization from scratch, some important libraries for tokenization are:\n",
    "- Numpy: Numerical computations\n",
    "- Pandas: Data manipulation\n",
    "- NLTK: tokenization using library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac291d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/silvercule/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import kagglehub\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3229f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/harshagarwal/.cache/kagglehub/datasets/selimkhaled50/new-data/versions/1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"selimkhaled50/new-data\")\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bf46909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New-data.json']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f19e8fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'tag': 'greeting', 'patterns': ['Is anyone th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'tag': 'morning', 'patterns': ['it was great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'tag': 'afternoon', 'patterns': ['it is a nic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'tag': 'evening', 'patterns': ['it is a nice ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'tag': 'night', 'patterns': ['good evening.',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>{'tag': 'fact-28', 'patterns': ['if i am conce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>{'tag': 'fact-29', 'patterns': ['i am not sure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>{'tag': 'fact-30', 'patterns': ['how can i kee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>{'tag': 'fact-31', 'patterns': ['there is a di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>{'tag': 'fact-32', 'patterns': ['there are dif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              intents\n",
       "0   {'tag': 'greeting', 'patterns': ['Is anyone th...\n",
       "1   {'tag': 'morning', 'patterns': ['it was great ...\n",
       "2   {'tag': 'afternoon', 'patterns': ['it is a nic...\n",
       "3   {'tag': 'evening', 'patterns': ['it is a nice ...\n",
       "4   {'tag': 'night', 'patterns': ['good evening.',...\n",
       "..                                                ...\n",
       "75  {'tag': 'fact-28', 'patterns': ['if i am conce...\n",
       "76  {'tag': 'fact-29', 'patterns': ['i am not sure...\n",
       "77  {'tag': 'fact-30', 'patterns': ['how can i kee...\n",
       "78  {'tag': 'fact-31', 'patterns': ['there is a di...\n",
       "79  {'tag': 'fact-32', 'patterns': ['there are dif...\n",
       "\n",
       "[80 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pd.read_json(os.path.join(path, os.listdir(path)[0]))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87cd6728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'tag': 'greeting',\n",
       "  'patterns': ['Is anyone there?',\n",
       "   'Ola',\n",
       "   'Hey there',\n",
       "   'Hi there',\n",
       "   'Howdy',\n",
       "   'Konnichiwa',\n",
       "   'Guten tag',\n",
       "   'Hi',\n",
       "   'Hola',\n",
       "   'Hey',\n",
       "   'Bonjour',\n",
       "   'Hello'],\n",
       "  'responses': ['Hello there. Tell me how are you feeling today?',\n",
       "   'Hi there. What brings you here today?',\n",
       "   'Hi there. How are you feeling today?',\n",
       "   'Great to see you. How do you feel currently?',\n",
       "   \"Hello there. Glad to see you're back. What's going on in your world right now?\"]},\n",
       " dict_keys(['tag', 'patterns', 'responses']))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.loc[0, 'intents'], text.loc[0, 'intents'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68bd5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>patterns</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greeting</td>\n",
       "      <td>Is anyone there? Ola Hey there Hi there Howdy ...</td>\n",
       "      <td>Hello there. Tell me how are you feeling today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morning</td>\n",
       "      <td>it was great to wake up. a good start to the d...</td>\n",
       "      <td>Good morning. I hope you had a good night's sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>it is a nice day. a good start to the day. goo...</td>\n",
       "      <td>Good afternoon. How is your day going?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evening</td>\n",
       "      <td>it is a nice day. it is a nice morning. it was...</td>\n",
       "      <td>Good evening. How has your day been?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>night</td>\n",
       "      <td>good evening. Good night it was nice. it was a...</td>\n",
       "      <td>Good night. Get some proper sleep Good night. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>fact-28</td>\n",
       "      <td>if i am concerned about my mental health, what...</td>\n",
       "      <td>The most important thing is to talk to someone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>fact-29</td>\n",
       "      <td>i am not sure if i'm well. if i'm not feeling ...</td>\n",
       "      <td>If your beliefs , thoughts , feelings or behav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>fact-30</td>\n",
       "      <td>how can i keep in touch with people? can i sta...</td>\n",
       "      <td>A lot of people are alone right now, but we do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>fact-31</td>\n",
       "      <td>there is a difference between stress and anxie...</td>\n",
       "      <td>Stress and anxiety are often used interchangea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>fact-32</td>\n",
       "      <td>there are differences between sadness and depr...</td>\n",
       "      <td>Sadness is a normal reaction to a loss, disapp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tag                                           patterns  \\\n",
       "0    greeting  Is anyone there? Ola Hey there Hi there Howdy ...   \n",
       "1     morning  it was great to wake up. a good start to the d...   \n",
       "2   afternoon  it is a nice day. a good start to the day. goo...   \n",
       "3     evening  it is a nice day. it is a nice morning. it was...   \n",
       "4       night  good evening. Good night it was nice. it was a...   \n",
       "..        ...                                                ...   \n",
       "75    fact-28  if i am concerned about my mental health, what...   \n",
       "76    fact-29  i am not sure if i'm well. if i'm not feeling ...   \n",
       "77    fact-30  how can i keep in touch with people? can i sta...   \n",
       "78    fact-31  there is a difference between stress and anxie...   \n",
       "79    fact-32  there are differences between sadness and depr...   \n",
       "\n",
       "                                            responses  \n",
       "0   Hello there. Tell me how are you feeling today...  \n",
       "1   Good morning. I hope you had a good night's sl...  \n",
       "2              Good afternoon. How is your day going?  \n",
       "3                Good evening. How has your day been?  \n",
       "4   Good night. Get some proper sleep Good night. ...  \n",
       "..                                                ...  \n",
       "75  The most important thing is to talk to someone...  \n",
       "76  If your beliefs , thoughts , feelings or behav...  \n",
       "77  A lot of people are alone right now, but we do...  \n",
       "78  Stress and anxiety are often used interchangea...  \n",
       "79  Sadness is a normal reaction to a loss, disapp...  \n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['tag'] = text.intents.apply(lambda x: x['tag'])\n",
    "text['patterns'] = text.intents.apply(lambda x: ' '.join(x['patterns']))\n",
    "text['responses'] = text.intents.apply(lambda x: ' '.join(x['responses']))\n",
    "\n",
    "text.drop(columns=['intents'], inplace=True)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e85236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['greeting', 'morning', 'afternoon', 'evening', 'night', 'goodbye',\n",
       "       'thanks', 'no-response', 'neutral-response', 'about', 'skill',\n",
       "       'creation', 'name', 'help', 'sad', 'stressed', 'worthless',\n",
       "       'depressed', 'happy', 'casual', 'anxious', 'not-talking', 'sleep',\n",
       "       'scared', 'death', 'understand', 'done', 'suicide', 'hate-you',\n",
       "       'hate-me', 'default', 'jokes', 'repeat', 'wrong', 'stupid',\n",
       "       'location', 'something-else', 'friends', 'ask', 'problem',\n",
       "       'no-approach', 'learn-more', 'user-agree', 'meditation',\n",
       "       'user-meditation', 'pandora-useful', 'user-advice',\n",
       "       'learn-mental-health', 'mental-health-fact', 'fact-1', 'fact-2',\n",
       "       'fact-3', 'fact-5', 'fact-6', 'fact-7', 'fact-8', 'fact-9',\n",
       "       'fact-10', 'fact-11', 'fact-12', 'fact-13', 'fact-14', 'fact-15',\n",
       "       'fact-16', 'fact-17', 'fact-18', 'fact-19', 'fact-20', 'fact-21',\n",
       "       'fact-22', 'fact-23', 'fact-24', 'fact-25', 'fact-26', 'fact-27',\n",
       "       'fact-28', 'fact-29', 'fact-30', 'fact-31', 'fact-32'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tag.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b3fc29",
   "metadata": {},
   "source": [
    "## Text preprocessing\n",
    "\n",
    "**Steps are:**\n",
    "- Removing punctuation\n",
    "- lowercasing\n",
    "- Revmoving stopwords\n",
    "- stemming/lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb32deb",
   "metadata": {},
   "source": [
    "#### Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f451c58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    return ''.join(i for i in list(text) if i not in string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d608e1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>patterns</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greeting</td>\n",
       "      <td>Is anyone there Ola Hey there Hi there Howdy K...</td>\n",
       "      <td>Hello there Tell me how are you feeling today ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morning</td>\n",
       "      <td>it was great to wake up a good start to the da...</td>\n",
       "      <td>Good morning I hope you had a good nights slee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>it is a nice day a good start to the day good ...</td>\n",
       "      <td>Good afternoon How is your day going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evening</td>\n",
       "      <td>it is a nice day it is a nice morning it was a...</td>\n",
       "      <td>Good evening How has your day been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>night</td>\n",
       "      <td>good evening Good night it was nice it was a n...</td>\n",
       "      <td>Good night Get some proper sleep Good night Sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>fact28</td>\n",
       "      <td>if i am concerned about my mental health what ...</td>\n",
       "      <td>The most important thing is to talk to someone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>fact29</td>\n",
       "      <td>i am not sure if im well if im not feeling wel...</td>\n",
       "      <td>If your beliefs  thoughts  feelings or behavio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>fact30</td>\n",
       "      <td>how can i keep in touch with people can i stay...</td>\n",
       "      <td>A lot of people are alone right now but we don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>fact31</td>\n",
       "      <td>there is a difference between stress and anxie...</td>\n",
       "      <td>Stress and anxiety are often used interchangea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>fact32</td>\n",
       "      <td>there are differences between sadness and depr...</td>\n",
       "      <td>Sadness is a normal reaction to a loss disappo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tag                                           patterns  \\\n",
       "0    greeting  Is anyone there Ola Hey there Hi there Howdy K...   \n",
       "1     morning  it was great to wake up a good start to the da...   \n",
       "2   afternoon  it is a nice day a good start to the day good ...   \n",
       "3     evening  it is a nice day it is a nice morning it was a...   \n",
       "4       night  good evening Good night it was nice it was a n...   \n",
       "..        ...                                                ...   \n",
       "75     fact28  if i am concerned about my mental health what ...   \n",
       "76     fact29  i am not sure if im well if im not feeling wel...   \n",
       "77     fact30  how can i keep in touch with people can i stay...   \n",
       "78     fact31  there is a difference between stress and anxie...   \n",
       "79     fact32  there are differences between sadness and depr...   \n",
       "\n",
       "                                            responses  \n",
       "0   Hello there Tell me how are you feeling today ...  \n",
       "1   Good morning I hope you had a good nights slee...  \n",
       "2                Good afternoon How is your day going  \n",
       "3                  Good evening How has your day been  \n",
       "4   Good night Get some proper sleep Good night Sw...  \n",
       "..                                                ...  \n",
       "75  The most important thing is to talk to someone...  \n",
       "76  If your beliefs  thoughts  feelings or behavio...  \n",
       "77  A lot of people are alone right now but we don...  \n",
       "78  Stress and anxiety are often used interchangea...  \n",
       "79  Sadness is a normal reaction to a loss disappo...  \n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = text.copy()\n",
    "texts['patterns'] = texts.patterns.apply(lambda x: remove_punctuations(x))\n",
    "texts['responses'] = texts.responses.apply(lambda x: remove_punctuations(x))\n",
    "texts['tag'] = texts.tag.apply(lambda x: remove_punctuations(x))\n",
    "\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cbaa83",
   "metadata": {},
   "source": [
    "#### Lowercasing alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78871a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>patterns</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greeting</td>\n",
       "      <td>is anyone there ola hey there hi there howdy k...</td>\n",
       "      <td>hello there tell me how are you feeling today ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morning</td>\n",
       "      <td>it was great to wake up a good start to the da...</td>\n",
       "      <td>good morning i hope you had a good nights slee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>it is a nice day a good start to the day good ...</td>\n",
       "      <td>good afternoon how is your day going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evening</td>\n",
       "      <td>it is a nice day it is a nice morning it was a...</td>\n",
       "      <td>good evening how has your day been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>night</td>\n",
       "      <td>good evening good night it was nice it was a n...</td>\n",
       "      <td>good night get some proper sleep good night sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>fact28</td>\n",
       "      <td>if i am concerned about my mental health what ...</td>\n",
       "      <td>the most important thing is to talk to someone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>fact29</td>\n",
       "      <td>i am not sure if im well if im not feeling wel...</td>\n",
       "      <td>if your beliefs  thoughts  feelings or behavio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>fact30</td>\n",
       "      <td>how can i keep in touch with people can i stay...</td>\n",
       "      <td>a lot of people are alone right now but we don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>fact31</td>\n",
       "      <td>there is a difference between stress and anxie...</td>\n",
       "      <td>stress and anxiety are often used interchangea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>fact32</td>\n",
       "      <td>there are differences between sadness and depr...</td>\n",
       "      <td>sadness is a normal reaction to a loss disappo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tag                                           patterns  \\\n",
       "0    greeting  is anyone there ola hey there hi there howdy k...   \n",
       "1     morning  it was great to wake up a good start to the da...   \n",
       "2   afternoon  it is a nice day a good start to the day good ...   \n",
       "3     evening  it is a nice day it is a nice morning it was a...   \n",
       "4       night  good evening good night it was nice it was a n...   \n",
       "..        ...                                                ...   \n",
       "75     fact28  if i am concerned about my mental health what ...   \n",
       "76     fact29  i am not sure if im well if im not feeling wel...   \n",
       "77     fact30  how can i keep in touch with people can i stay...   \n",
       "78     fact31  there is a difference between stress and anxie...   \n",
       "79     fact32  there are differences between sadness and depr...   \n",
       "\n",
       "                                            responses  \n",
       "0   hello there tell me how are you feeling today ...  \n",
       "1   good morning i hope you had a good nights slee...  \n",
       "2                good afternoon how is your day going  \n",
       "3                  good evening how has your day been  \n",
       "4   good night get some proper sleep good night sw...  \n",
       "..                                                ...  \n",
       "75  the most important thing is to talk to someone...  \n",
       "76  if your beliefs  thoughts  feelings or behavio...  \n",
       "77  a lot of people are alone right now but we don...  \n",
       "78  stress and anxiety are often used interchangea...  \n",
       "79  sadness is a normal reaction to a loss disappo...  \n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "texts['patterns'] = texts.patterns.apply(lambda x: convert_to_lowercase(x))\n",
    "texts['responses'] = texts.responses.apply(lambda x: convert_to_lowercase(x))\n",
    "texts['tag'] = texts.tag.apply(lambda x: convert_to_lowercase(x))\n",
    "\n",
    "texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbff1070",
   "metadata": {},
   "source": [
    "### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "404c0894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/harshagarwal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b29cdbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"he's\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "559967d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c216031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>patterns</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greeting</td>\n",
       "      <td>anyone ola hey hi howdy konnichiwa guten tag h...</td>\n",
       "      <td>hello tell feeling today hi brings today hi fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morning</td>\n",
       "      <td>great wake good start day great start day good...</td>\n",
       "      <td>good morning hope good nights sleep feeling today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>nice day good start day good day good afternoo...</td>\n",
       "      <td>good afternoon day going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evening</td>\n",
       "      <td>nice day nice morning good night good morning ...</td>\n",
       "      <td>good evening day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>night</td>\n",
       "      <td>good evening good night nice nice day good nig...</td>\n",
       "      <td>good night get proper sleep good night sweet d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>fact28</td>\n",
       "      <td>concerned mental health im worried mental heal...</td>\n",
       "      <td>important thing talk someone trust might frien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>fact29</td>\n",
       "      <td>sure im well im feeling well know im well know...</td>\n",
       "      <td>beliefs thoughts feelings behaviours significa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>fact30</td>\n",
       "      <td>keep touch people stay touch friends done main...</td>\n",
       "      <td>lot people alone right dont lonely together th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>fact31</td>\n",
       "      <td>difference stress anxiety stress anxiety diffe...</td>\n",
       "      <td>stress anxiety often used interchangeably over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>fact32</td>\n",
       "      <td>differences sadness depression depression sadn...</td>\n",
       "      <td>sadness normal reaction loss disappointment pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tag                                           patterns  \\\n",
       "0    greeting  anyone ola hey hi howdy konnichiwa guten tag h...   \n",
       "1     morning  great wake good start day great start day good...   \n",
       "2   afternoon  nice day good start day good day good afternoo...   \n",
       "3     evening  nice day nice morning good night good morning ...   \n",
       "4       night  good evening good night nice nice day good nig...   \n",
       "..        ...                                                ...   \n",
       "75     fact28  concerned mental health im worried mental heal...   \n",
       "76     fact29  sure im well im feeling well know im well know...   \n",
       "77     fact30  keep touch people stay touch friends done main...   \n",
       "78     fact31  difference stress anxiety stress anxiety diffe...   \n",
       "79     fact32  differences sadness depression depression sadn...   \n",
       "\n",
       "                                            responses  \n",
       "0   hello tell feeling today hi brings today hi fe...  \n",
       "1   good morning hope good nights sleep feeling today  \n",
       "2                            good afternoon day going  \n",
       "3                                    good evening day  \n",
       "4   good night get proper sleep good night sweet d...  \n",
       "..                                                ...  \n",
       "75  important thing talk someone trust might frien...  \n",
       "76  beliefs thoughts feelings behaviours significa...  \n",
       "77  lot people alone right dont lonely together th...  \n",
       "78  stress anxiety often used interchangeably over...  \n",
       "79  sadness normal reaction loss disappointment pr...  \n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts['patterns'] = texts.patterns.apply(lambda x: remove_stopwords(x))\n",
    "texts['responses'] = texts.responses.apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f124b4",
   "metadata": {},
   "source": [
    "Now we have pre-processed data.\n",
    "\n",
    "\n",
    "### Sentence tokenizer and word tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c31d988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/harshagarwal/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import  sent_tokenize, word_tokenize\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a74f876d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello, how are you?', 'I am fine.', 'Thank you.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(\"Hello, how are you? I am fine. Thank you.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d58a1f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " ',',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'I',\n",
       " 'am',\n",
       " 'fine',\n",
       " '.',\n",
       " 'Thank',\n",
       " 'you',\n",
       " '.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"Hello, how are you? I am fine. Thank you.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0971fe",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatization\n",
    "\n",
    "We will apply\n",
    "- Stemming on patterns column, and\n",
    "- Lemmatization on responses columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadea580",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4dfce3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/harshagarwal/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1374f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('program', 'programming')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"programming\", \"v\"), lemmatizer.lemmatize(\"programming\", \"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ce2f40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('programming is a fun activity', 'program be a fun activity')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lematize_text_n(text):\n",
    "    return ' '.join(lemmatizer.lemmatize(word, pos=\"n\") for word in text.split())\n",
    "\n",
    "def lematize_text_v(text):\n",
    "    return ' '.join(lemmatizer.lemmatize(word, pos=\"v\") for word in text.split())\n",
    "\n",
    "lematize_text_n(\"programming is a fun activity\"), lematize_text_v(\"programming is a fun activity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36861237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>patterns</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greeting</td>\n",
       "      <td>anyone ola hey hi howdy konnichiwa guten tag h...</td>\n",
       "      <td>hello tell feeling today hi brings today hi fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morning</td>\n",
       "      <td>great wake good start day great start day good...</td>\n",
       "      <td>good morning hope good nights sleep feeling today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>nice day good start day good day good afternoo...</td>\n",
       "      <td>good afternoon day going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evening</td>\n",
       "      <td>nice day nice morning good night good morning ...</td>\n",
       "      <td>good evening day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>night</td>\n",
       "      <td>good even good night nice nice day good night ...</td>\n",
       "      <td>good night get proper sleep good night sweet d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>fact28</td>\n",
       "      <td>concern mental health im worry mental health i...</td>\n",
       "      <td>important thing talk someone trust might frien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>fact29</td>\n",
       "      <td>sure im well im feel well know im well know po...</td>\n",
       "      <td>beliefs thoughts feelings behaviours significa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>fact30</td>\n",
       "      <td>keep touch people stay touch friend do maintai...</td>\n",
       "      <td>lot people alone right dont lonely together th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>fact31</td>\n",
       "      <td>difference stress anxiety stress anxiety diffe...</td>\n",
       "      <td>stress anxiety often used interchangeably over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>fact32</td>\n",
       "      <td>difference sadness depression depression sadne...</td>\n",
       "      <td>sadness normal reaction loss disappointment pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tag                                           patterns  \\\n",
       "0    greeting  anyone ola hey hi howdy konnichiwa guten tag h...   \n",
       "1     morning  great wake good start day great start day good...   \n",
       "2   afternoon  nice day good start day good day good afternoo...   \n",
       "3     evening  nice day nice morning good night good morning ...   \n",
       "4       night  good even good night nice nice day good night ...   \n",
       "..        ...                                                ...   \n",
       "75     fact28  concern mental health im worry mental health i...   \n",
       "76     fact29  sure im well im feel well know im well know po...   \n",
       "77     fact30  keep touch people stay touch friend do maintai...   \n",
       "78     fact31  difference stress anxiety stress anxiety diffe...   \n",
       "79     fact32  difference sadness depression depression sadne...   \n",
       "\n",
       "                                            responses  \n",
       "0   hello tell feeling today hi brings today hi fe...  \n",
       "1   good morning hope good nights sleep feeling today  \n",
       "2                            good afternoon day going  \n",
       "3                                    good evening day  \n",
       "4   good night get proper sleep good night sweet d...  \n",
       "..                                                ...  \n",
       "75  important thing talk someone trust might frien...  \n",
       "76  beliefs thoughts feelings behaviours significa...  \n",
       "77  lot people alone right dont lonely together th...  \n",
       "78  stress anxiety often used interchangeably over...  \n",
       "79  sadness normal reaction loss disappointment pr...  \n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts['patterns'] = texts.patterns.apply(lambda x: lematize_text_v(x))\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29edd4b0",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ddd5ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dadab8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('program', 'program')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmer.stem(\"programming\"), stemmer.stem(\"program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7212e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'program is a fun activ'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stem_text(text):\n",
    "    return \" \".join(stemmer.stem(word) for word in text.split())\n",
    "\n",
    "stem_text(\"programming is a fun activity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00116724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>patterns</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greeting</td>\n",
       "      <td>anyone ola hey hi howdy konnichiwa guten tag h...</td>\n",
       "      <td>hello tell feel today hi bring today hi feel t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morning</td>\n",
       "      <td>great wake good start day great start day good...</td>\n",
       "      <td>good morn hope good night sleep feel today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>nice day good start day good day good afternoo...</td>\n",
       "      <td>good afternoon day go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evening</td>\n",
       "      <td>nice day nice morning good night good morning ...</td>\n",
       "      <td>good even day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>night</td>\n",
       "      <td>good even good night nice nice day good night ...</td>\n",
       "      <td>good night get proper sleep good night sweet d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>fact28</td>\n",
       "      <td>concern mental health im worry mental health i...</td>\n",
       "      <td>import thing talk someon trust might friend co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>fact29</td>\n",
       "      <td>sure im well im feel well know im well know po...</td>\n",
       "      <td>belief thought feel behaviour signific impact ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>fact30</td>\n",
       "      <td>keep touch people stay touch friend do maintai...</td>\n",
       "      <td>lot peopl alon right dont lone togeth think di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>fact31</td>\n",
       "      <td>difference stress anxiety stress anxiety diffe...</td>\n",
       "      <td>stress anxieti often use interchang overlap st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>fact32</td>\n",
       "      <td>difference sadness depression depression sadne...</td>\n",
       "      <td>sad normal reaction loss disappoint problem di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tag                                           patterns  \\\n",
       "0    greeting  anyone ola hey hi howdy konnichiwa guten tag h...   \n",
       "1     morning  great wake good start day great start day good...   \n",
       "2   afternoon  nice day good start day good day good afternoo...   \n",
       "3     evening  nice day nice morning good night good morning ...   \n",
       "4       night  good even good night nice nice day good night ...   \n",
       "..        ...                                                ...   \n",
       "75     fact28  concern mental health im worry mental health i...   \n",
       "76     fact29  sure im well im feel well know im well know po...   \n",
       "77     fact30  keep touch people stay touch friend do maintai...   \n",
       "78     fact31  difference stress anxiety stress anxiety diffe...   \n",
       "79     fact32  difference sadness depression depression sadne...   \n",
       "\n",
       "                                            responses  \n",
       "0   hello tell feel today hi bring today hi feel t...  \n",
       "1          good morn hope good night sleep feel today  \n",
       "2                               good afternoon day go  \n",
       "3                                       good even day  \n",
       "4   good night get proper sleep good night sweet d...  \n",
       "..                                                ...  \n",
       "75  import thing talk someon trust might friend co...  \n",
       "76  belief thought feel behaviour signific impact ...  \n",
       "77  lot peopl alon right dont lone togeth think di...  \n",
       "78  stress anxieti often use interchang overlap st...  \n",
       "79  sad normal reaction loss disappoint problem di...  \n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts['responses'] = texts.responses.apply(lambda x: stem_text(x))\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ffc37f",
   "metadata": {},
   "source": [
    "With this, we complete basic tokenization.\n",
    "\n",
    "Now all the text data in above dataframe is well tokenized, ready to be embedded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769b01da",
   "metadata": {},
   "source": [
    "### Tokenization in NLP v/s LLM\n",
    "\n",
    "Now once it is clear how these pre-processing methods works, one this is certain and is easy to recognize, that - *This is not the best way, many relevant information are missed out!*. Since these are important, we must come up with a way to tokenize in better way. Here comes \"Byte pair encoding - subword tokenization method\" that doesn't remove anything from the text, and works best too! **And most importantly, it works for any language, no matter how complicated the language is!** Isn't that awesome? We'll study this in other tutorial in detail. But keep in mind that it is one of the best method to tokenize, and is used in LLMs as well!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "silvercule",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
